{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiameseNets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "_SidAHK3Y23t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja-86SIMsDyc",
        "outputId": "863a38ad-18ed-4c8b-88a9-112e458b7ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/MyDrive/Deep Learning/SiameseNets'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jfGsQLVinVS",
        "outputId": "2e92ea2e-42be-43f9-9e8f-f975d9c84695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Deep Learning/SiameseNets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "KKdYL-mi-hz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining utility functions"
      ],
      "metadata": {
        "id": "sjH17foBY9hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read .pgm image\n",
        "def read_image(filename, byteorder='>'):\n",
        "    #first we read the image, as a raw file to the buffer\n",
        "    with open(filename, 'rb') as f:\n",
        "        buffer = f.read()\n",
        "    \n",
        "    #using regex, we extract the header, width, height and maxval of the image\n",
        "    header, width, height, maxval = re.search(\n",
        "        b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
        "    \n",
        "    #then we convert the image to numpy array using np.frombuffer which interprets buffer as one dimensional array\n",
        "    return np.frombuffer(buffer,\n",
        "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
        "                            count=int(width)*int(height),\n",
        "                            offset=len(header)\n",
        "                            ).reshape((int(height), int(width)))"
      ],
      "metadata": {
        "id": "qLndW0qtV5Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_image('./Dataset/s1/1.pgm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWR1CZC_hj7E",
        "outputId": "a884ae6e-fa02-4893-f384-80e29fb559b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[48, 49, 45, ..., 56, 56, 54],\n",
              "       [45, 52, 39, ..., 52, 50, 51],\n",
              "       [45, 50, 42, ..., 48, 53, 50],\n",
              "       ...,\n",
              "       [50, 48, 50, ..., 45, 46, 46],\n",
              "       [45, 54, 49, ..., 46, 47, 47],\n",
              "       [51, 51, 51, ..., 47, 46, 46]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = 2\n",
        "total_sample_size = 10000\n",
        "\n",
        "# Function to generate similar and dissimilar image pairs from the dataset\n",
        "def get_data(size, total_sample_size):\n",
        "    #read the image\n",
        "    image = read_image('./Dataset/s' + str(1) + '/' + str(1) + '.pgm', 'rw+')\n",
        "    #reduce the size\n",
        "    image = image[::size, ::size]\n",
        "    #get the new size\n",
        "    dim1 = image.shape[0]\n",
        "    dim2 = image.shape[1]\n",
        "\n",
        "    count = 0\n",
        "    \n",
        "    #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
        "    x_geuine_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2]) # 2 is for pairs\n",
        "    y_genuine = np.zeros([total_sample_size, 1])\n",
        "    \n",
        "    for i in range(40):\n",
        "        for j in range(int(total_sample_size/40)):\n",
        "            ind1 = 0\n",
        "            ind2 = 0\n",
        "            \n",
        "            #read images from same directory (genuine pair)\n",
        "            while ind1 == ind2:\n",
        "                ind1 = np.random.randint(10)\n",
        "                ind2 = np.random.randint(10)\n",
        "            \n",
        "            # read the two images\n",
        "            img1 = read_image('./Dataset/s' + str(i+1) + '/' + str(ind1 + 1) + '.pgm', 'rw+')\n",
        "            img2 = read_image('./Dataset/s' + str(i+1) + '/' + str(ind2 + 1) + '.pgm', 'rw+')\n",
        "            \n",
        "            #reduce the size\n",
        "            img1 = img1[::size, ::size]\n",
        "            img2 = img2[::size, ::size]\n",
        "            \n",
        "            #store the images to the initialized numpy array\n",
        "            x_geuine_pair[count, 0, 0, :, :] = img1\n",
        "            x_geuine_pair[count, 1, 0, :, :] = img2\n",
        "            \n",
        "            #as we are drawing images from the same directory we assign label as 1. (genuine pair)\n",
        "            y_genuine[count] = 1\n",
        "            count += 1\n",
        "\n",
        "    count = 0\n",
        "    x_imposite_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])\n",
        "    y_imposite = np.zeros([total_sample_size, 1])\n",
        "    \n",
        "    for i in range(int(total_sample_size/10)):\n",
        "        for j in range(10):\n",
        "            \n",
        "            #read images from different directory (imposite pair)\n",
        "            while True:\n",
        "                ind1 = np.random.randint(40)\n",
        "                ind2 = np.random.randint(40)\n",
        "                if ind1 != ind2:\n",
        "                    break\n",
        "                    \n",
        "            img1 = read_image('./Dataset/s' + str(ind1+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
        "            img2 = read_image('./Dataset/s' + str(ind2+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
        "\n",
        "            img1 = img1[::size, ::size]\n",
        "            img2 = img2[::size, ::size]\n",
        "\n",
        "            x_imposite_pair[count, 0, 0, :, :] = img1\n",
        "            x_imposite_pair[count, 1, 0, :, :] = img2\n",
        "            #as we are drawing images from the different directory we assign label as 0. (imposite pair)\n",
        "            y_imposite[count] = 0\n",
        "            count += 1\n",
        "            \n",
        "    #now, concatenate, genuine pairs and opposite pair to get the whole data\n",
        "    X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255\n",
        "    Y = np.concatenate([y_genuine, y_imposite], axis=0)\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "Pnmxlt9YjDlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = get_data(size, total_sample_size)"
      ],
      "metadata": {
        "id": "C3R1D5v4q2CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)"
      ],
      "metadata": {
        "id": "5ceyoL2OtOfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of Siamese Network"
      ],
      "metadata": {
        "id": "Mep7nUoEZHe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_base_network(input_shape):\n",
        "    \n",
        "    seq = Sequential()\n",
        "    \n",
        "    nb_filter = [6, 12]\n",
        "    kernel_size = 3\n",
        "    \n",
        "    \n",
        "    #convolutional layer 1\n",
        "    seq.add(Convolution2D(nb_filter[0], kernel_size, kernel_size, input_shape=input_shape,\n",
        "                          padding='valid', data_format=\"channels_first\"))\n",
        "    seq.add(Activation('relu'))\n",
        "    seq.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")) \n",
        "    seq.add(Dropout(.25))\n",
        "    \n",
        "    #convolutional layer 2\n",
        "    seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, padding='valid', data_format=\"channels_first\"))\n",
        "    seq.add(Activation('relu'))\n",
        "    seq.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")) \n",
        "    seq.add(Dropout(.25))\n",
        "\n",
        "    #flatten \n",
        "    seq.add(Flatten())\n",
        "    seq.add(Dense(128, activation='relu'))\n",
        "    seq.add(Dropout(0.1))\n",
        "    seq.add(Dense(50, activation='relu'))\n",
        "    return seq"
      ],
      "metadata": {
        "id": "C05-IAxrtbGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = x_train.shape[2:]\n",
        "img_a = Input(shape=input_dim)\n",
        "img_b = Input(shape=input_dim)\n",
        "\n",
        "base_network = build_base_network(input_dim)\n",
        "feat_vecs_a = base_network(img_a)\n",
        "feat_vecs_b = base_network(img_b)"
      ],
      "metadata": {
        "id": "BHcFlrWRvkCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])"
      ],
      "metadata": {
        "id": "qv3EYOo0xBNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "rms = RMSprop()\n",
        "\n",
        "model = Model(inputs=[img_a, img_b], outputs=distance)"
      ],
      "metadata": {
        "id": "ajfhOJiyxFcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
        "\n",
        "model.compile(loss=contrastive_loss, optimizer=rms)"
      ],
      "metadata": {
        "id": "wespykCKyRlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing"
      ],
      "metadata": {
        "id": "8fc_A4dNZUnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_1 = x_train[:, 0]\n",
        "img_2 = x_train[:, 1] \n",
        "print(img_1.shape, img_2.shape)\n",
        "model.fit([img_1, img_2], y_train, validation_split=.25, batch_size=128, verbose=2, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGtjKB5pyk-y",
        "outputId": "ad31511e-e707-4655-a2de-7a166e5a6540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15000, 1, 56, 46) (15000, 1, 56, 46)\n",
            "Epoch 1/30\n",
            "88/88 - 2s - loss: 0.1893 - val_loss: 0.1982 - 2s/epoch - 24ms/step\n",
            "Epoch 2/30\n",
            "88/88 - 1s - loss: 0.1864 - val_loss: 0.1881 - 749ms/epoch - 9ms/step\n",
            "Epoch 3/30\n",
            "88/88 - 1s - loss: 0.1836 - val_loss: 0.1870 - 712ms/epoch - 8ms/step\n",
            "Epoch 4/30\n",
            "88/88 - 1s - loss: 0.1774 - val_loss: 0.1759 - 720ms/epoch - 8ms/step\n",
            "Epoch 5/30\n",
            "88/88 - 1s - loss: 0.1762 - val_loss: 0.1688 - 712ms/epoch - 8ms/step\n",
            "Epoch 6/30\n",
            "88/88 - 1s - loss: 0.1746 - val_loss: 0.1804 - 728ms/epoch - 8ms/step\n",
            "Epoch 7/30\n",
            "88/88 - 1s - loss: 0.1734 - val_loss: 0.1663 - 731ms/epoch - 8ms/step\n",
            "Epoch 8/30\n",
            "88/88 - 1s - loss: 0.1719 - val_loss: 0.1658 - 712ms/epoch - 8ms/step\n",
            "Epoch 9/30\n",
            "88/88 - 1s - loss: 0.1688 - val_loss: 0.1552 - 706ms/epoch - 8ms/step\n",
            "Epoch 10/30\n",
            "88/88 - 1s - loss: 0.1667 - val_loss: 0.1522 - 699ms/epoch - 8ms/step\n",
            "Epoch 11/30\n",
            "88/88 - 1s - loss: 0.1660 - val_loss: 0.1547 - 688ms/epoch - 8ms/step\n",
            "Epoch 12/30\n",
            "88/88 - 1s - loss: 0.1647 - val_loss: 0.1490 - 750ms/epoch - 9ms/step\n",
            "Epoch 13/30\n",
            "88/88 - 1s - loss: 0.1630 - val_loss: 0.1515 - 736ms/epoch - 8ms/step\n",
            "Epoch 14/30\n",
            "88/88 - 1s - loss: 0.1597 - val_loss: 0.1484 - 702ms/epoch - 8ms/step\n",
            "Epoch 15/30\n",
            "88/88 - 1s - loss: 0.1601 - val_loss: 0.1481 - 737ms/epoch - 8ms/step\n",
            "Epoch 16/30\n",
            "88/88 - 1s - loss: 0.1617 - val_loss: 0.1527 - 738ms/epoch - 8ms/step\n",
            "Epoch 17/30\n",
            "88/88 - 1s - loss: 0.1597 - val_loss: 0.1470 - 743ms/epoch - 8ms/step\n",
            "Epoch 18/30\n",
            "88/88 - 1s - loss: 0.1577 - val_loss: 0.1433 - 690ms/epoch - 8ms/step\n",
            "Epoch 19/30\n",
            "88/88 - 1s - loss: 0.1571 - val_loss: 0.1393 - 691ms/epoch - 8ms/step\n",
            "Epoch 20/30\n",
            "88/88 - 1s - loss: 0.1570 - val_loss: 0.1434 - 700ms/epoch - 8ms/step\n",
            "Epoch 21/30\n",
            "88/88 - 1s - loss: 0.1545 - val_loss: 0.1427 - 705ms/epoch - 8ms/step\n",
            "Epoch 22/30\n",
            "88/88 - 1s - loss: 0.1549 - val_loss: 0.1346 - 748ms/epoch - 8ms/step\n",
            "Epoch 23/30\n",
            "88/88 - 1s - loss: 0.1554 - val_loss: 0.1378 - 688ms/epoch - 8ms/step\n",
            "Epoch 24/30\n",
            "88/88 - 1s - loss: 0.1520 - val_loss: 0.1338 - 702ms/epoch - 8ms/step\n",
            "Epoch 25/30\n",
            "88/88 - 1s - loss: 0.1545 - val_loss: 0.1364 - 741ms/epoch - 8ms/step\n",
            "Epoch 26/30\n",
            "88/88 - 1s - loss: 0.1520 - val_loss: 0.1338 - 713ms/epoch - 8ms/step\n",
            "Epoch 27/30\n",
            "88/88 - 1s - loss: 0.1521 - val_loss: 0.1323 - 760ms/epoch - 9ms/step\n",
            "Epoch 28/30\n",
            "88/88 - 1s - loss: 0.1503 - val_loss: 0.1308 - 714ms/epoch - 8ms/step\n",
            "Epoch 29/30\n",
            "88/88 - 1s - loss: 0.1508 - val_loss: 0.1407 - 716ms/epoch - 8ms/step\n",
            "Epoch 30/30\n",
            "88/88 - 1s - loss: 0.1496 - val_loss: 0.1343 - 694ms/epoch - 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f242016bb50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict([x_test[:, 0], x_test[:, 1]])"
      ],
      "metadata": {
        "id": "P1I_9jGjyqKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(predictions, labels):\n",
        "    return labels[predictions.ravel() < 0.5].mean()"
      ],
      "metadata": {
        "id": "ZcqSlwxw20fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdUvNWQT2_ll",
        "outputId": "1fcf7d97-6093-4760-8809-d6b301d45725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7357366771159874"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}